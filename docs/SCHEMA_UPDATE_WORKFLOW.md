# Schema Update Workflow

This guide explains how to maintain and update the schema-driven documentation infrastructure.

## Overview

The documentation system is built on three pillars:

1. **JSON Schema** (`docs/schemas/docstring-schema.json`) - Source of truth
2. **Pydantic Models** (`opt/docstring_models.py`) - Generated from schema
3. **Validation Scripts** (`scripts/`) - Use Pydantic models for validation

## When to Update the Schema

Update the schema when you need to:

- Add new required or optional sections to docstrings
- Change field validation rules (e.g., allowed values, patterns)
- Add new metadata fields
- Modify existing field constraints

## Schema Update Process

### Step 1: Edit the JSON Schema

Edit `docs/schemas/docstring-schema.json`:

```json
{
  "definitions": {
    "AlgorithmMetadata": {
      "properties": {
        "new_field": {
          "type": "string",
          "description": "Description of new field"
        }
      }
    }
  }
}
```

### Step 2: Validate the JSON Schema

```bash
# Check that the schema is valid JSON
python -c "import json; json.load(open('docs/schemas/docstring-schema.json'))"
```

### Step 3: Regenerate Pydantic Models

```bash
# Regenerate opt/docstring_models.py from updated schema
uv run datamodel-codegen \
  --input docs/schemas/docstring-schema.json \
  --output opt/docstring_models.py \
  --input-file-type jsonschema \
  --output-model-type pydantic_v2.BaseModel \
  --use-standard-collections \
  --use-schema-description \
  --field-constraints \
  --snake-case-field \
  --use-default \
  --target-python-version 3.10
```

### Step 4: Update Module Docstring

Add/update the module docstring in `opt/docstring_models.py`:

```python
"""Pydantic models for validating optimizer docstrings.

This module contains Pydantic models generated from the JSON schema
defined in docs/schemas/docstring-schema.json.

Generated by datamodel-codegen:
  filename:  docstring-schema.json
  timestamp: YYYY-MM-DDTHH:MM:SS+00:00
"""
```

### Step 5: Fix Any Linting Issues

```bash
# Format the generated code
uv run ruff format opt/docstring_models.py

# Check for issues
uv run ruff check opt/docstring_models.py

# If needed, add to per-file-ignores in pyproject.toml
```

### Step 6: Update Parser if Needed

If you added new sections or changed parsing logic, update `scripts/docstring_parser.py`:

```python
def parse_new_section(self, content: str) -> dict | None:
    """Parse the new section."""
    # Add parsing logic
    pass
```

### Step 7: Update Tests

Add tests for new fields in `opt/test/test_docstring_models.py`:

```python
def test_new_field_validation(self) -> None:
    """Test validation of new field."""
    metadata = AlgorithmMetadata(
        # ... existing fields
        new_field="test value",
    )
    assert metadata.new_field == "test value"
```

### Step 8: Run Tests

```bash
# Run all docstring tests
uv run pytest opt/test/test_docstring_models.py opt/test/test_docstring_parser.py -v

# Verify all pass
```

### Step 9: Update Documentation

Update `scripts/README.md` if the changes affect usage:

```markdown
## New Feature

Description of what changed and how to use it.
```

### Step 10: Commit Changes

```bash
git add docs/schemas/docstring-schema.json
git add opt/docstring_models.py
git add scripts/docstring_parser.py
git add opt/test/test_docstring_models.py
git add scripts/README.md
git commit -m "feat: update docstring schema - add new_field"
```

## Common Schema Modifications

### Adding a New Enum Value

```json
{
  "definitions": {
    "AlgorithmClass": {
      "enum": [
        "Swarm Intelligence",
        "Evolutionary",
        "New Category"  // Add this
      ]
    }
  }
}
```

### Adding Optional Field

```json
{
  "properties": {
    "new_optional_field": {
      "type": "string",
      "description": "Optional field description"
      // No "required" array entry = optional
    }
  }
}
```

### Adding Required Field

```json
{
  "required": [
    "algorithm_metadata",
    "new_required_field"  // Add to required array
  ],
  "properties": {
    "new_required_field": {
      "type": "string",
      "description": "Required field description"
    }
  }
}
```

### Changing Validation Pattern

```json
{
  "properties": {
    "acronym": {
      "type": "string",
      "pattern": "^[A-Z][A-Z0-9-]*$"  // Update regex
    }
  }
}
```

## Validation Pipeline

After schema updates, the validation pipeline automatically checks:

1. **Pre-commit Hook** - Validates modified files
2. **CI/CD** - Validates all files on PR
3. **Schema Consistency** - Ensures schema is valid JSON
4. **Pydantic Import** - Verifies models can be imported

## Troubleshooting

### Issue: Pydantic model generation fails

**Solution**: Check JSON schema syntax:
```bash
python -c "import json; json.load(open('docs/schemas/docstring-schema.json'))"
```

### Issue: Import errors after regeneration

**Solution**: Check for Python syntax errors:
```bash
python -m py_compile opt/docstring_models.py
```

### Issue: Tests fail after schema update

**Solution**: Update test data to match new schema constraints:
```python
# Old test
metadata = AlgorithmMetadata(acronym="invalid")  # May fail with new pattern

# Updated test
metadata = AlgorithmMetadata(acronym="VALID")  # Matches new pattern
```

### Issue: Validation too strict/loose

**Solution**: Adjust schema constraints:
```json
// Too strict
"pattern": "^[A-Z]+$"

// More lenient
"pattern": "^[A-Za-z0-9-]+$"
```

## Best Practices

1. **Always validate JSON** before regenerating models
2. **Run full test suite** after schema changes
3. **Update documentation** when adding new fields
4. **Add examples** for new validation rules
5. **Consider backward compatibility** when removing fields
6. **Version the schema** for major changes

## Related Files

- Schema: `docs/schemas/docstring-schema.json`
- Models: `opt/docstring_models.py`
- Parser: `scripts/docstring_parser.py`
- Validator: `scripts/unified_validator.py`
- Tests: `opt/test/test_docstring_models.py`, `opt/test/test_docstring_parser.py`
- Config: `.pre-commit-config.yaml`, `.github/workflows/docs-validation.yml`
