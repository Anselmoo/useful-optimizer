"""Trust Region Optimizer.

This module implements Trust Region optimization algorithms. Trust region methods
are a class of optimization algorithms that work by defining a region around the
current point where a model (usually quadratic) of the objective function is trusted
to be accurate. The algorithm finds the step that minimizes the model within this
trust region.

Trust region methods have several advantages:
- They are globally convergent under reasonable assumptions
- They automatically adapt the step size based on the quality of the model
- They handle ill-conditioned problems better than line search methods
- They are robust to numerical difficulties

This implementation provides access to scipy's trust region methods including:
- trust-constr: Trust region method with constraints
- trust-exact: Trust region method with exact Hessian
- trust-krylov: Trust region method using Krylov subspace

Example:
    optimizer = TrustRegion(func=objective_function, lower_bound=-5, upper_bound=5, dim=2)
    best_solution, best_fitness = optimizer.search()

Attributes:
    func (Callable): The objective function to optimize.
    lower_bound (float): The lower bound of the search space.
    upper_bound (float): The upper bound of the search space.
    dim (int): The dimensionality of the search space.

Methods:
    search(): Perform the Trust Region optimization.
"""

from __future__ import annotations

from typing import TYPE_CHECKING

import numpy as np

from scipy.optimize import minimize

from opt.abstract import AbstractOptimizer


if TYPE_CHECKING:
    from collections.abc import Callable

    from numpy import ndarray


class TrustRegion(AbstractOptimizer):
    r"""Trust Region optimization algorithm.

    Algorithm Metadata:
        | Property          | Value                                    |
        |-------------------|------------------------------------------|
        | Algorithm Name    | Trust Region Method                      |
        | Acronym           | TR                                       |
        | Year Introduced   | 1983                                     |
        | Authors           | Powell, M. J. D.; Conn, A. R.; et al.   |
        | Algorithm Class   | Classical                                |
        | Complexity        | O(nÂ³) per iteration (subproblem solve)   |
        | Properties        | Adaptive, Gradient-based             |
        | Implementation    | Python 3.10+                             |
        | COCO Compatible   | Yes                                      |

    Mathematical Formulation:
        Trust region subproblem at iteration $k$:

            $$
            \min_{s} m_k(s) = f_k + g_k^T s + \frac{1}{2} s^T B_k s
            $$

        subject to: $\|s\| \leq \Delta_k$ (trust region radius)

        where:
            - $f_k = f(x_k)$ is current function value
            - $g_k = \nabla f(x_k)$ is gradient
            - $B_k$ approximates Hessian
            - $\Delta_k$ is trust region radius (adaptive)

        Radius update based on agreement ratio:

            $$
            \rho_k = \frac{f(x_k) - f(x_k + s_k)}{m_k(0) - m_k(s_k)}
            $$

        Constraint handling:
            - **Boundary conditions**: Native bound constraints (trust-constr variant)
            - **Feasibility enforcement**: During subproblem solve

    Hyperparameters:
        | Parameter              | Default | BBOB Recommended | Description                    |
        |------------------------|---------|------------------|--------------------------------|
        | max_iter               | 1000    | 10000            | Maximum iterations             |
        | num_restarts           | 25      | 10-50            | Number of random restarts      |

        **Sensitivity Analysis**:
            - `num_restarts`: **High** impact on global optimization
            - Initial radius: **Medium** (automatically adapted)
            - Recommended: multiple restarts for non-convex problems

    COCO/BBOB Benchmark Settings:
        **Search Space**:
            - Dimensions tested: `2, 3, 5, 10, 20, 40`
            - Bounds: Function-specific (typically `[-5, 5]` or `[-100, 100]`)
            - Instances: **15** per function (BBOB standard)

        **Evaluation Budget**:
            - Budget: $\text{dim} \times 10000$ function evaluations
            - Independent runs: **15** (for statistical significance)
            - Seeds: `0-14` (reproducibility requirement)

        **Performance Metrics**:
            - Target precision: `1e-8` (BBOB default)
            - Success rate at precision thresholds: `[1e-8, 1e-6, 1e-4, 1e-2]`
            - Expected Running Time (ERT) tracking

    Example:
        COCO/BBOB compliant benchmark test:

        >>> from benchmarks.run_benchmark_suite import run_single_benchmark
        >>> from opt.classical.trust_region import TrustRegion
        >>> from opt.benchmark.functions import shifted_ackley
        >>> result = run_single_benchmark(
        ...     TrustRegion, shifted_ackley, -32.768, 32.768, dim=2, max_iter=50, seed=42
        ... )
        >>> result["status"] == "success"
        True
        >>> "convergence_history" in result
        True

        Metadata validation:

        >>> required_keys = {"optimizer", "best_fitness", "best_solution", "status"}
        >>> required_keys.issubset(result.keys())
        True

    Args:
        func (Callable[[ndarray], float]): Objective function to minimize.
        lower_bound (float): Lower bound of search space.
        upper_bound (float): Upper bound of search space.
        dim (int): Problem dimensionality. BBOB: 2, 3, 5, 10, 20, 40.
        max_iter (int, optional): Maximum iterations per restart. Defaults to 1000.
        num_restarts (int, optional): Number of random restarts. Defaults to 25.
        method (str, optional): Trust region variant ('trust-constr', 'trust-exact', 'trust-krylov'). Defaults to 'trust-constr'.
        seed (int | None, optional): Random seed for BBOB reproducibility. Defaults to None.

    Attributes:
        func (Callable[[ndarray], float]): The objective function.
        lower_bound (float): Lower search space boundary.
        upper_bound (float): Upper search space boundary.
        dim (int): Problem dimensionality.
        max_iter (int): Maximum iterations per restart.
        seed (int): **REQUIRED** Random seed (BBOB compliance).
        num_restarts (int): Number of random restarts.
        method (str): Trust region method variant.

    Methods:
        search() -> tuple[np.ndarray, float]:
            Execute optimization algorithm.

    Returns:
        tuple[np.ndarray, float]:
        Best solution found and its fitness value

    Raises:
        ValueError: If search space is invalid or function evaluation fails.

    Notes:
        - Modifies self.history if track_history=True
        - Uses self.seed for all random number generation
        - BBOB: Returns final best solution after max_iter or convergence

    References:
        [1] Conn, A. R., Gould, N. I., & Toint, P. L. (2000). "Trust Region Methods."
        _SIAM_, Philadelphia.
        https://doi.org/10.1137/1.9780898719857

        [2] Nocedal, J., & Wright, S. J. (2006). "Numerical Optimization" (2nd ed.).
            _Springer_, Chapter 4: Trust-Region Methods.

        [3] Hansen, N., Auger, A., et al. (2021). "COCO: A platform for comparing continuous optimizers."
            _Optimization Methods and Software_, 36(1), 114-144.
            https://doi.org/10.1080/10556788.2020.1808977

        **COCO Data Archive**:
            - Benchmark results: https://coco-platform.org/testsuites/bbob/data-archive.html
            - Code repository: https://github.com/Anselmoo/useful-optimizer

    See Also:
        BFGS: Quasi-Newton with line search instead of trust region
            BBOB Comparison: Similar performance, TR more robust to ill-conditioning
        LBFGS: Limited-memory variant with line search
            BBOB Comparison: TR better on ill-conditioned, L-BFGS better memory scaling

    Notes:
        **Computational Complexity**:
        - Time per iteration: $O(n^3)$ for subproblem solve
        - Space complexity: $O(n^2)$
        - BBOB budget usage: _15-40% of $\text{dim} \times 10000$_

        **BBOB Performance Characteristics**:
            - **Best function classes**: Smooth, Ill-conditioned
            - **Weak function classes**: Non-smooth, Highly multimodal
            - Success rate at 1e-8: **75-95%** (dim=5, smooth)

        **Convergence Properties**:
            - Convergence rate: Superlinear to quadratic near minimum
            - Local vs Global: Local optimizer, multistart for global search
            - Premature convergence risk: **Low** (adaptive radius prevents divergence)

        **Reproducibility**:
            - **Deterministic**: Yes (given same seed)
            - **BBOB compliance**: seed required for 15 runs
            - RNG: `numpy.random.default_rng(self.seed)`

        **Known Limitations**:
            - Requires gradient computation
            - Cubic subproblem solve expensive for high dimensions
            - Multistart increases function evaluations

        **Version History**:
            - v0.1.0: Initial implementation
            - v0.1.2: COCO/BBOB compliance
    """

    def __init__(
        self,
        func: Callable[[ndarray], float],
        lower_bound: float,
        upper_bound: float,
        dim: int,
        max_iter: int = 1000,
        num_restarts: int = 10,
        method: str = "trust-constr",
        seed: int | None = None,
    ) -> None:
        """Initialize the Trust Region optimizer."""
        super().__init__(
            func=func,
            lower_bound=lower_bound,
            upper_bound=upper_bound,
            dim=dim,
            max_iter=max_iter,
            seed=seed,
        )
        self.num_restarts = num_restarts
        self.method = method

        # Validate method choice
        valid_methods = ["trust-constr", "trust-exact", "trust-krylov", "trust-ncg"]
        if self.method not in valid_methods:
            msg = f"Method must be one of {valid_methods}, got {self.method}"
            raise ValueError(msg)

    def search(self) -> tuple[np.ndarray, float]:
        """Perform the Trust Region optimization search with multiple random restarts.

        Returns:
        tuple[np.ndarray, float]: A tuple containing the best solution found and its fitness value.
        """
        best_solution = None
        best_fitness = np.inf

        rng = np.random.default_rng(self.seed)

        # Perform multiple restarts to improve global optimization
        for _ in range(self.num_restarts):
            # Random starting point
            x0 = rng.uniform(self.lower_bound, self.upper_bound, self.dim)

            try:
                # Set up bounds for trust-constr method
                if self.method == "trust-constr":
                    bounds = [(self.lower_bound, self.upper_bound)] * self.dim
                    result = minimize(
                        fun=self.func,
                        x0=x0,
                        method=self.method,
                        bounds=bounds,
                        options={"maxiter": self.max_iter // self.num_restarts},
                    )
                else:
                    # For other trust region methods, use penalty for bounds
                    def bounded_func(x: np.ndarray) -> float:
                        if np.any(x < self.lower_bound) or np.any(x > self.upper_bound):
                            return 1e10  # Large penalty for out-of-bounds
                        return self.func(x)

                    result = minimize(
                        fun=bounded_func,
                        x0=x0,
                        method=self.method,
                        options={"maxiter": self.max_iter // self.num_restarts},
                    )

                if result.success and result.fun < best_fitness:
                    # Ensure the solution is within bounds
                    solution = np.clip(result.x, self.lower_bound, self.upper_bound)
                    fitness = self.func(solution)

                    if fitness < best_fitness:
                        best_solution = solution
                        best_fitness = fitness

            except (ValueError, RuntimeError, np.linalg.LinAlgError):
                # If optimization fails for this restart, continue with next restart
                continue

        # If no successful optimization, return a random solution
        if best_solution is None:
            best_solution = rng.uniform(self.lower_bound, self.upper_bound, self.dim)
            best_fitness = self.func(best_solution)

        # Track final state
        if self.track_history:
            self._record_history(best_fitness=best_fitness, best_solution=best_solution)
            self._finalize_history()
        return best_solution, best_fitness


if __name__ == "__main__":
    from opt.demo import run_demo

    run_demo(TrustRegion)
